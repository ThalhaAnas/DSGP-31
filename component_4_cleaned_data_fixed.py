# -*- coding: utf-8 -*-
"""Component_4 Cleaned Data_Fixed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_OAUincJeELONH6olwSXvY6AnxgERRw0

Import Required Libraries
"""

import pandas as pd
import numpy as np

"""Load the Raw Dataset"""

df = pd.read_csv("/content/component4_performance_fixed.csv")

"""Create a Working Copy"""

df_clean = df.copy()

"""Initial Structure Check"""

df_clean.shape
df_clean.head()
df_clean.info()

"""Handle Duplicate Records"""

# Check duplicates
duplicates = df_clean.duplicated().sum()
print("Duplicate rows:", duplicates)

# Remove duplicates if present
df_clean.drop_duplicates(inplace=True)

"""Missing Value Analysis"""

df_clean.isnull().sum()

# Numerical columns
num_cols = df_clean.select_dtypes(include=["int64", "float64"]).columns

for col in num_cols:
    df_clean[col] = df_clean[col].fillna(df_clean[col].median())


# Categorical columns
cat_cols = df_clean.select_dtypes(include=["object"]).columns

for col in cat_cols:
    df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])

"""Data Type Validation & Correction"""

for col in num_cols:
    df_clean[col] = pd.to_numeric(df_clean[col], errors="coerce")

df_clean.info()

"""Logical Constraint Validation"""

for col in num_cols:
    df_clean = df_clean[df_clean[col] >= 0]

"""Outlier Treatment (IQR Capping â€“ FIXED TIME APPROACH)"""

def iqr_cap(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    df[column] = np.where(
        df[column] < lower, lower,
        np.where(df[column] > upper, upper, df[column])
    )
    return df

"""Apply to All Numerical Columns"""

for col in num_cols:
    df_clean = iqr_cap(df_clean, col)

"""Categorical Data Standardization"""

for col in cat_cols:
    df_clean[col] = df_clean[col].str.strip().str.lower()

"""Feature Scaling (Post-Cleaning Only)"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_clean[num_cols] = scaler.fit_transform(df_clean[num_cols])

"""Final Clean Dataset Validation"""

df_clean.shape
df_clean.info()
df_clean.describe()

"""Save Cleaned Dataset

"""

df_clean.to_csv("component4_cleaned_dataset.csv", index=False)